---
title: "DGFM: Full Body Dance Generation Driven by Music Foundation Models"
date: 2025-02-28T00:00:00
authors: ["Xinran Liu", "Zhenhua Feng", "Diptesh Kanojia", "Wenwu Wang"]
publication_types: ["3"]
abstract: "In music-driven dance motion generation, most existing methods use hand-crafted features and neglect that music foundation models have profoundly impacted cross-modal content generation. To bridge this gap, we propose a diffusion-based method that generates dance movements conditioned on text and music. Our approach extracts music features by combining high-level features obtained by music foundation model with hand-crafted features, thereby enhancing the quality of generated dance sequences. This method effectively leverages the advantages of high-level semantic information and low-level temporal details to improve the model's capability in music feature understanding. To show the merits of the proposed method, we compare it with four music foundation models and two sets of hand-crafted music features. The results demonstrate that our method obtains the most realistic dance sequences and achieves the best match with the input music."
featured: false
publication: "*arXiv preprint arXiv:2502.20176*"
url_pdf: "https://arxiv.org/abs/2502.20176"
url_preprint: "https://arxiv.org/abs/2502.20176"
tags: ["dance generation", "music foundation models", "diffusion", "cross-modal"]
---