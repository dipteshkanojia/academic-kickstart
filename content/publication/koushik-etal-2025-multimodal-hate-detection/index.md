---
title: "Towards a Robust Framework for Multimodal Hate Detection: A Study on Video vs. Image-based Content"
date: 2025-05-23T00:00:00
authors: ["Girish A Koushik", "Diptesh Kanojia", "Helen Treharne"]
publication_types: ["1"]
abstract: "Social media platforms enable the propagation of hateful content across different modalities such as textual, auditory, and visual, necessitating effective detection methods. While recent approaches have shown promise in handling individual modalities, their effectiveness across different modality combinations remains unexplored. Our paper presents a systematic analysis of fusion-based approaches for multimodal hate detection, focusing on performance across video and image-based content. Our comprehensive evaluation reveals significant modality-specific limitations: while simple embedding fusion achieves state-of-the-art performance on video content with a 9.9% points F1-score improvement, it struggles with complex image-text relationships in memes. Through detailed ablation studies and error analysis, we demonstrate how current fusion approaches fail to capture nuanced cross-modal interactions, particularly in cases involving benign confounders. Our findings provide crucial insights for developing more robust hate detection systems and highlight the need for modality-specific architectural considerations. The code is available at: https://github.com/surrey-nlp/Video-vs-Meme-Hate. **Note:** Awarded the Best Paper at the MM4SG workshop @ WWW 2025."
featured: true
publication: "*Companion Proceedings of the ACM on Web Conference 2025 (WWW 2025)*"
url_pdf: "https://doi.org/10.1145/3701716.3718382"
url_code: "https://github.com/surrey-nlp/Video-vs-Meme-Hate"
url_video: "https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3701716.3718382&file=wk1104-video.mp4.mp4"
url_slides: "files/ppt-mm4sg-www-2025-hate.pdf"
tags: ["multimodal", "hate-detection", "video", "image", "social-media", "fusion-methods"]
---
